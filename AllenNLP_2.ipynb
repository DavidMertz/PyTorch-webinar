{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing with AllenNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\">What is AllenNLP?</font>\n",
    "<a href=\"AllenNLP_0.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">What is SpaCy?</font>\n",
    "<a href=\"AllenNLP_1.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\"><b><u>High Level Interfaces to NLP using PyTorch</u></b></font>\n",
    "<a href=\"AllenNLP_2.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">Sentiment Analysis</font>\n",
    "<a href=\"AllenNLP_3.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">Part-of-Speech Tagging</font> \n",
    "<a href=\"AllenNLP_4.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## High Level Interfaces to NLP using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An [Apache 2.0](https://github.com/allenai/allennlp/blob/master/LICENSE) NLP research library, built on PyTorch,\n",
    "for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.\n",
    "\n",
    "The below is simply the README file from the [project GitHub page](https://github.com/allenai)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Overview\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td><b> allennlp </b></td>\n",
    "    <td> an open-source NLP research library, built on PyTorch </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b> allennlp.commands </b></td>\n",
    "    <td> functionality for a CLI and web service </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b> allennlp.data </b></td>\n",
    "    <td> a data processing module for loading datasets and encoding strings as integers for representation in matrices </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b> allennlp.models </b></td>\n",
    "    <td> a collection of state-of-the-art models </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b> allennlp.modules </b></td>\n",
    "    <td> a collection of PyTorch modules for use with text </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b> allennlp.nn </b></td>\n",
    "    <td> tensor utility functions, such as initializers and activation functions </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b> allennlp.service </b></td>\n",
    "    <td> a web server to that can serve demos for your models </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b> allennlp.training </b></td>\n",
    "    <td> functionality for training models </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "AllenNLP requires Python 3.6.1 or later. The preferred way to install AllenNLP is via `pip`.  Just run `pip install allennlp` in your Python environment and you're good to go!\n",
    "\n",
    "If you need pointers on setting up an appropriate Python environment or would like to install AllenNLP using a different method, see below.\n",
    "\n",
    "Windows is currently not officially supported, although we try to fix issues when they are easily addressed.\n",
    "\n",
    "#### Installing via pip\n",
    "\n",
    "##### Setting up a virtual environment\n",
    "\n",
    "[Conda](https://conda.io/) can be used set up a virtual environment with the\n",
    "version of Python required for AllenNLP.  If you already have a Python 3.6 or 3.7\n",
    "environment you want to use, you can skip to the 'installing via pip' section.\n",
    "\n",
    "1.  [Download and install Conda](https://conda.io/docs/download.html).\n",
    "\n",
    "2.  Create a Conda environment with Python 3.6\n",
    "\n",
    "    ```bash\n",
    "    conda create -n allennlp python=3.6\n",
    "    ```\n",
    "\n",
    "3.  Activate the Conda environment. You will need to activate the Conda environment in each terminal in which you want to use AllenNLP.\n",
    "\n",
    "    ```bash\n",
    "    source activate allennlp\n",
    "    ```\n",
    "\n",
    "##### Installing the library and dependencies\n",
    "\n",
    "Installing the library and dependencies is simple using `pip`.\n",
    "\n",
    "   ```bash\n",
    "   pip install allennlp\n",
    "   ```\n",
    "\n",
    "That's it! You're now ready to build and train AllenNLP models.\n",
    "AllenNLP installs a script when you install the python package, meaning you can run allennlp commands just by typing `allennlp` into a terminal.\n",
    "\n",
    "You can now test your installation with `allennlp test-install`.\n",
    "\n",
    "_`pip` currently installs Pytorch for CUDA 9 only (or no GPU). If you require an older version,\n",
    "please visit http://pytorch.org/ and install the relevant pytorch binary._\n",
    "\n",
    "#### Installing using Docker\n",
    "\n",
    "Docker provides a virtual machine with everything set up to run AllenNLP--\n",
    "whether you will leverage a GPU or just run on a CPU.  Docker provides more\n",
    "isolation and consistency, and also makes it easy to distribute your\n",
    "environment to a compute cluster.\n",
    "\n",
    "Once you have [installed Docker](https://docs.docker.com/engine/installation/)\n",
    "just run the following command to get an environment that will run on either the cpu or gpu.\n",
    "\n",
    "   ```bash\n",
    "   mkdir -p $HOME/.allennlp/\n",
    "   docker run --rm -v $HOME/.allennlp:/root/.allennlp allennlp/allennlp:v0.8.3\n",
    "   ```\n",
    "\n",
    "You can test the Docker environment with `docker run --rm -v $HOME/.allennlp:/root/.allennlp allennlp/allennlp:v0.8.3 test-install`.\n",
    "\n",
    "### Installing from source\n",
    "\n",
    "You can also install AllenNLP by cloning our git repository:\n",
    "\n",
    "  ```bash\n",
    "  git clone https://github.com/allenai/allennlp.git\n",
    "  ```\n",
    "\n",
    "Create a Python 3.6 virtual environment, and install AllenNLP in `editable` mode by running:\n",
    "\n",
    "  ```bash\n",
    "  pip install --editable .\n",
    "  ```\n",
    "\n",
    "This will make `allennlp` available on your system but it will use the sources from the local clone\n",
    "you made of the source repository.\n",
    "\n",
    "You can test your installation with `allennlp test-install`.\n",
    "The full development environment also requires the JVM and `perl`,\n",
    "which must be installed separately.  `./scripts/verify.py` will run\n",
    "the full suite of tests used by our continuous build environment.\n",
    "\n",
    "## Running AllenNLP\n",
    "\n",
    "Once you've installed AllenNLP, you can run the command-line interface either\n",
    "with the `allennlp` command (if you installed via `pip`) or `allennlp` (if you installed via source).\n",
    "\n",
    "```bash\n",
    "$ allennlp\n",
    "Run AllenNLP\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help    show this help message and exit\n",
    "  --version     show program's version number and exit\n",
    "\n",
    "Commands:\n",
    "\n",
    "    configure   Run the configuration wizard.\n",
    "    train       Train a model.\n",
    "    evaluate    Evaluate the specified model + dataset.\n",
    "    predict     Use a trained model to make predictions.\n",
    "    make-vocab  Create a vocabulary.\n",
    "    elmo        Create word vectors using a pretrained ELMo model.\n",
    "    fine-tune   Continue training a model on a new dataset.\n",
    "    dry-run     Create a vocabulary, compute dataset statistics and other\n",
    "                training utilities.\n",
    "    test-install\n",
    "                Run the unit tests.\n",
    "    find-lr     Find a learning rate range.\n",
    "```\n",
    "\n",
    "## Docker images\n",
    "\n",
    "AllenNLP releases Docker images to [Docker Hub](https://hub.docker.com/r/allennlp/) for each release.  For information on how to run these releases, see [Installing using Docker](#installing-using-docker).\n",
    "\n",
    "### Building a Docker image\n",
    "\n",
    "For various reasons you may need to create your own AllenNLP Docker image.\n",
    "The same image can be used either with a CPU or a GPU.\n",
    "\n",
    "First, you need to [install Docker](https://www.docker.com/get-started).\n",
    "Then run the following command\n",
    "(it will take some time, as it completely builds the\n",
    "environment needed to run AllenNLP.)\n",
    "\n",
    "```bash\n",
    "docker build -f Dockerfile.pip --tag allennlp/allennlp:latest .\n",
    "```\n",
    "\n",
    "You should now be able to see this image listed by running `docker images allennlp`.\n",
    "\n",
    "```\n",
    "REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n",
    "allennlp/allennlp            latest              b66aee6cb593        5 minutes ago       2.38GB\n",
    "```\n",
    "\n",
    "#### Running the Docker image\n",
    "\n",
    "You can run the image with `docker run --rm -it allennlp/allennlp:latest`.  The `--rm` flag cleans up the image on exit and the `-it` flags make the session interactive so you can use the bash shell the Docker image starts.\n",
    "\n",
    "You can test your installation by running  `allennlp test-install`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues\n",
    "\n",
    "Everyone is welcome to file issues with either feature requests, bug reports, or general questions.  As a small team with our own internal goals, we may ask for contributions if a prompt fix doesn't fit into our roadmap.  We allow users a two week window to follow up on questions, after which we will close issues.  They can be re-opened if there is further discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributions\n",
    "\n",
    "The AllenNLP team at AI2 (@allenai) welcomes contributions from the greater AllenNLP community, and, if you would like to get a change into the library, this is likely the fastest approach.  If you would like to contribute a larger feature, we recommend first creating an issue with a proposed design for discussion.  This will prevent you from spending significant time on an implementation which has a technical limitation someone could have pointed out early on.  Small contributions can be made directly in a pull request.\n",
    "\n",
    "Pull requests (PRs) must have one approving review and no requested changes before they are merged.  As AllenNLP is primarily driven by AI2 (@allenai) we reserve the right to reject or revert contributions that we don't think are good additions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citing\n",
    "\n",
    "If you use AllenNLP in your research, please cite [AllenNLP: A Deep Semantic Natural Language Processing Platform](https://www.semanticscholar.org/paper/AllenNLP%3A-A-Deep-Semantic-Natural-Language-Platform-Gardner-Grus/a5502187140cdd98d76ae711973dbcdaf1fef46d).\n",
    "\n",
    "```\n",
    "@inproceedings{Gardner2017AllenNLP,\n",
    "  title={AllenNLP: A Deep Semantic Natural Language Processing Platform},\n",
    "  author={Matt Gardner and Joel Grus and Mark Neumann and Oyvind Tafjord\n",
    "    and Pradeep Dasigi and Nelson F. Liu and Matthew Peters and\n",
    "    Michael Schmitz and Luke S. Zettlemoyer},\n",
    "  year={2017},\n",
    "  Eprint = {arXiv:1803.07640},\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team\n",
    "\n",
    "AllenNLP is an open-source project backed by [the Allen Institute for Artificial Intelligence (AI2)](http://www.allenai.org).\n",
    "AI2 is a non-profit institute with the mission to contribute to humanity through high-impact AI research and engineering.\n",
    "To learn more about who specifically contributed to this codebase, see [our contributors](https://github.com/allenai/allennlp/graphs/contributors) page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
