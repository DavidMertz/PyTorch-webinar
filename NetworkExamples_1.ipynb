{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks with Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\">A simple feature classifier</font>\n",
    "<a href=\"NetworkExamples_0.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\"><u><b>An image classifier</b></u></font>\n",
    "<a href=\"NetworkExamples_1.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">A regression prediction</font>\n",
    "<a href=\"NetworkExamples_2.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">Clustering with PyTorch</font>\n",
    "<a href=\"NetworkExamples_3.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">Generative Adversarial Networks (GAN)</font> \n",
    "<a href=\"NetworkExamples_4.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">Part of Speech Tagger</font>\n",
    "<a href=\"NetworkExamples_5.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch.nn import Sequential, Conv2d, MaxPool2d, Linear, Module\n",
    "import torch.optim as optim\n",
    "\n",
    "# For demonstration, we can use CPU target if CUDA not available\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Check the status of the GPU (if present)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA memory used:\", torch.cuda.memory_allocated())\n",
    "    device = torch.device('cuda') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An image classifier\n",
    "\n",
    "To get a feel for an image classifier, let us setup one very close to that presented in the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).  We will change a few details and add some commentary, but most of the code follows that.  \n",
    "\n",
    "One notable change is that by adjusting learning rate in the training loop, we achieve considerably better results than in the tutorial while using an identical network.\n",
    "\n",
    "The output of torchvision datasets are PILImage images of range `[0, 1]`. We transform them to Tensors of normalized range `[-1, 1]`.  I.e.:\n",
    "\n",
    "```\n",
    "# For one color plane\n",
    "pixel = (pixel - mean) / std\n",
    "# (0-0.5) / 0.5 == -1\n",
    "# (1-0.5) / 0.5 == 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "transform = Compose([\n",
    "    Resize(32),\n",
    "    ToTensor(),\n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show an image\n",
    "def imshow(images):\n",
    "    grid = make_grid(images, padding=2, pad_value=2, nrow=4)\n",
    "    grid = grid/2 + 0.5     # denormalize [-1, 1] -> [0, 1]\n",
    "    npimg = grid.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images and labels\n",
    "imshow(images)\n",
    "print('Labels:', ' '.join(classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyTorch tutorial uses a more object-oriented style than shown.  I prefer the more declarative (and more concise) style of `torch.nn.Sequential`.  The OOP style requires a separate `.__init__()` method to configure layers, then a `.forward()` to actually utilize them.  To me, this feels excessively imperative and bug-prone.\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "```\n",
    "\n",
    "Unfortunately, the developers of PyTorch currently endorse the OOP style, and to that end of removed `torch.nn.View` as a separate declarative layer, making reshaping in layers more difficult.  We can work around that by creating our own `Flatten` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "   \n",
    "    def forward(self, x):\n",
    "        return x.view(-1, self.shape) \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.shape})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    Conv2d(3, 6, 5),\n",
    "    MaxPool2d(2, 2),\n",
    "    Conv2d(6, 16, 5),\n",
    "    MaxPool2d(2, 2),\n",
    "    Flatten(400),\n",
    "    Linear(400, 120),\n",
    "    Linear(120, 84),\n",
    "    Linear(84, 10)\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainable parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "print(\"Trainable parameters:\",\n",
    "      f\"{sum([np.prod(p.size()) for p in grad_params]):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time it takes for training to terminate and the final loss and model accuracy are very sensitive to the schedule of decaying the learning rate.  The below is a good compromise for this particular dataset, but I played around with numerous variations.  The best of these will reach a running loss of 0.89 and an accuracy of 63%.  Of course, I have not explored the entire near-infinite space of possible schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Expect ~9 min\n",
    "early_stop = 4\n",
    "running_loss = []  # Every loss computation\n",
    "loss_history = []  # Intermittent averages\n",
    "\n",
    "# Loop over the dataset multiple times\n",
    "for epoch in range(1, 100):  \n",
    "    for batch, data in enumerate(trainloader, 0):\n",
    "        # get the inputs, put them on GPU if available\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        running_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics periodically\n",
    "        if batch % 1000 == 999:\n",
    "            rloss = mean(running_loss[-1000:])\n",
    "            loss_history.append(rloss)\n",
    "            print(f'Epoch {epoch}; '\n",
    "                  f' Batch {batch+1:4d} '\n",
    "                  f'- Running-Loss: {rloss} '\n",
    "                  f'(lr={optimizer.param_groups[0][\"lr\"]:0.8f})')\n",
    "             \n",
    "            \n",
    "    ## Lower learning rate by 2x if no improvement in loss for multiple epochs\n",
    "    diff = max(loss_history[-early_stop:]) - min(loss_history[-early_stop:])\n",
    "    if  diff/loss_history[-1] < 0.02:\n",
    "        optimizer.param_groups[0]['lr'] /= 2 \n",
    "\n",
    "    ## If learning rate is lowered to tiny value, we are not getting anywhere\n",
    "    if optimizer.param_groups[0]['lr'] < 1e-8:           \n",
    "        print(\"+++ Discontinuing training regime when loss becomes constant\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()\n",
    "outputs = model(images.to(device))\n",
    "_, predict = torch.max(outputs.data, 1)\n",
    "\n",
    "# Print images\n",
    "imshow(images)\n",
    "\n",
    "# Show the ground truth\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Truth': labels.cpu(), 'Predict': predict.cpu()})\n",
    "df['Truth'] = df.Truth.map(lambda i: classes[i])\n",
    "df['Predict'] = df.Predict.map(lambda i: classes[i])\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success?\n",
    "\n",
    "I think this relatively simple model with 62k weights does reasonably well.  The CIFAR10 image dataset has ten (balanced) classes as its targets, so random selection would get an accuracy of 10%.  Of course, the leading edge images classifiers—with hundreds of layers and millions of trainable weights (in some cases [**billions**](https://arxiv.org/abs/1811.06965)!)—do quite a bit better than our sample network.  But this is not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "\n",
    "**Tasks with Networks**: We constructed a fairly good image classifier with just a bit of code.  Clearly, this classifier is less powerful than competition-winning leading ones with hundreds of layers; but just a few layers makes reasonably good predictions.  Next we will reframe the domain area classification problem we looked at in the last lesson as a regression problem.\n",
    "\n",
    "<a href=\"NetworkExamples_2.ipynb\"><img src=\"img/open-notebook.png\" align=\"left\"/></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
